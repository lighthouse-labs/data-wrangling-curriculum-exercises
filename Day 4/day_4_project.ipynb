{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import sqlite3\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Database\n",
    "- Download the database for project from [here](https://drive.google.com/file/d/1oJnQKRbh20DuOP2ejE2k4ZG7eOcqsmI-/view?usp=sharing)\n",
    "- Check the table names in the database. There should be 5 tables:\n",
    "    - transactions\n",
    "    - transactions_clean\n",
    "    - monthly_transaction_report\n",
    "    - monthly_agent_report\n",
    "    - monthly_product_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the job scenario:\n",
    "\n",
    "The **transactions** table in **project.db** contains transactions from 2019-01-01 to 2020-06-17. This table contains original (raw) data. The data for the period before 2020-01-01 was already cleaned and is stored in the same database, but in the separate table **transactions_clean** (Transaction Date < '2020-01-01').\n",
    "\n",
    "Imagine that an ETL process uploads new transaction data (the year 2020) every month to the table transactions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Task I: Leverage both SQL and Python to extract and clean data using data wrangling techniques\n",
    "\n",
    "Create the python program that pulls the \"new\" data from the database and removes unnecessary columns. The program should run monthly. For example:\n",
    "\n",
    "- On 1st of February 2020, it should take data where Transaction Date is between **'2020-01-01'** and **'2020-01-31'**\n",
    "- On 1st of March 2020, it should take data where Transaction Date is between **'2020-02-01'** and **'2020-02-29'**\n",
    "\n",
    "\n",
    "The following columns are unnecessary and should be removed:\n",
    "\n",
    "1. Columns that are completely empty (should be 4 columns)\n",
    "2. Constant columns (Policy Level Rate, Is Processed, New To Medicare, Company Business Unit Code)\n",
    "3. IDs and Names (should be 2 columns)\n",
    "4. Remove other redundant columns: Carrier Group and Product Code\n",
    "\n",
    "The final dataframe should have 18 columns.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task II: Create a Python script that cleans data and appends it to the appropriate table in the database\n",
    "\n",
    "Create a python program that checks and cleans the output of Task I and stores it (appends) in the table **transactions_clean**.\n",
    "\n",
    "- The column that requires our attention is **Transaction Code**. Its values are not consistent, using both upper and lower cases to represent the same thing.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task III: Extract data and create a report using Python\n",
    "\n",
    "We are working on the monthly reports. The reports should be exported in Excel and stored in the database tables. We will be using data in transactions_clean. We should pull the data based on the **Transaction Date**. For example:\n",
    "\n",
    "- On 1st of April, 2020 it should take data where Transaction Date is between **'2020-03-01'** and **'2020-03-31'**\n",
    "\n",
    "There are three reports already created in the tables:\n",
    "\n",
    "- monthly_transaction_report\n",
    "- monthly_product_report\n",
    "- monthly_agent_report\n",
    "\n",
    "We should take the \"new\" transactions and create a report from them and append to the tables above. The report for each month must have the same columns as SQL tables mentioned above.\n",
    "\n",
    "This process could obviously be done in SQL procedure as well and it even might be the best option in some cases. However, doing this in Python offers numerous advantages:\n",
    "\n",
    "- The report can be exported easily to CSV or Excel files\n",
    "- Python works as a simple connector to any other database running anywhere\n",
    "- It's very easy to create Python scripts that are scheduled to run on a regular basis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task IV: Automate reporting by scheduling Python script to run at specified times\n",
    "\n",
    "Schedule the run of **Task I - III** and simulate run from January to June 2020.\n",
    "\n",
    "- Schedule the process to run in 2-3 minutes so we can test if it starts automatically\n",
    "- We simulate the date by using datetime package in Python\n",
    "\n",
    "\n",
    "```python\n",
    "# code sample\n",
    "import datetime\n",
    "any_day = datetime.date(2020,3,1)\n",
    "print(any_day)\n",
    "today = datetime.date.today()\n",
    "print(today)\n",
    "```\n",
    "\n",
    "In this project, we will use the function **datetime.date(2020,3,1)** so we can run the script as it would run in March. In real life, we would replace it with **datetime.date.today()**\n",
    "\n",
    "We need to start by creating the function return_important_dates that returns the **first** and **last** day of the previous month.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "### Stretch: Task V\n",
    "\n",
    "Complete Tasks I, II, III using SQL only. Task IV remains the same in this Stretch Task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
